{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MXjYyH-ssE40"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1101,"status":"ok","timestamp":1749971653665,"user":{"displayName":"Root","userId":"10400991980939663586"},"user_tz":-180},"id":"L8_YLhrDgW7O","outputId":"62a883da-0dd1-4f7e-c37f-a9bbc526bd26"},"outputs":[{"name":"stdout","output_type":"stream","text":["📦 Extracting ZIP to temporary directory...\n","🧹 Removing old extract folder.\n","📁 Moving extracted image folder to: /content/tomato_ds\n","✅ Extraction and flattening complete: /content/tomato_ds\n"]}],"source":["import os\n","import zipfile\n","import shutil\n","from pathlib import Path\n","\n","def extract_and_flatten(zip_path, final_extract_path):\n","    temp_extract_path = Path(\"/content/temp_extract\")\n","\n","    # Step 0: Cleanup temp if it exists\n","    if temp_extract_path.exists():\n","        print(\"🧹 Cleaning up old temp directory...\")\n","        shutil.rmtree(temp_extract_path)\n","\n","    print(\"📦 Extracting ZIP to temporary directory...\")\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(temp_extract_path)\n","\n","    current = temp_extract_path\n","    while True:\n","        subdirs = [d for d in current.iterdir() if d.is_dir()]\n","        image_dirs = [\n","            d for d in subdirs if any(f.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"] for f in d.glob(\"*\"))\n","        ]\n","\n","        if image_dirs:\n","            break  \n","\n","        if len(subdirs) != 1:\n","            print(\"❌ Could not flatten — ambiguous or unexpected folder structure.\")\n","            return\n","\n","        current = subdirs[0]\n","\n","    if final_extract_path.exists():\n","        print(\"🧹 Removing old extract folder.\")\n","        shutil.rmtree(final_extract_path)\n","\n","    print(f\"📁 Moving extracted image folder to: {final_extract_path}\")\n","    shutil.move(str(current), final_extract_path)\n","\n","    if temp_extract_path.exists():\n","        shutil.rmtree(temp_extract_path)\n","\n","    print(f\"✅ Extraction and flattening complete: {final_extract_path}\")\n","\n","\n","# === USAGE ===\n","zip_path = \"/content/drive/MyDrive/Tomato_.zip\"\n","final_extract_path = Path(\"/content/tomato_ds\")\n","\n","extract_and_flatten(zip_path, final_extract_path)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EH48Ifq-anGB"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uK6woN5rs3CE"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":548,"status":"ok","timestamp":1749971697349,"user":{"displayName":"Root","userId":"10400991980939663586"},"user_tz":-180},"id":"nhJaS3zmlHPu","outputId":"35f43261-62f9-4064-e005-9545557f2f57"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Tomato_Early_blight: 800 train, 200 val\n","✅ Tomato_Late_blight: 1405 train, 352 val\n","✅ Tomato_healthy: 1272 train, 318 val\n","🎉 Dataset split into train/val complete.\n"]}],"source":["import os\n","import shutil\n","import random\n","from pathlib import Path\n","\n","def prepare_dataset(base_path, train_ratio=0.8):\n","    base_path = Path(base_path)\n","    train_path = base_path.parent / 'train'\n","    val_path = base_path.parent / 'val'\n","\n","    # if train_path.exists() and val_path.exists():\n","    #     print(\"✔️ Dataset already split.\")\n","    #     return\n","\n","    train_path.mkdir(parents=True, exist_ok=True)\n","    val_path.mkdir(parents=True, exist_ok=True)\n","\n","    # Each subfolder in PlantVillage is a class\n","    class_folders = [d for d in base_path.iterdir() if d.is_dir()]\n","\n","    for class_dir in class_folders:\n","        images = list(class_dir.glob(\"*.JPG\")) + list(class_dir.glob(\"*.png\")) + list(class_dir.glob(\"*.jpeg\"))\n","\n","        if len(images) < 2:\n","            print(f\"⚠️ Skipping {class_dir.name} — not enough images.\")\n","            continue\n","\n","        random.shuffle(images)\n","        split_idx = int(len(images) * train_ratio)\n","        train_imgs = images[:split_idx]\n","        val_imgs = images[split_idx:]\n","\n","        train_class_dir = train_path / class_dir.name\n","        val_class_dir = val_path / class_dir.name\n","        train_class_dir.mkdir(parents=True, exist_ok=True)\n","        val_class_dir.mkdir(parents=True, exist_ok=True)\n","\n","        for img in train_imgs:\n","            shutil.copy2(img, train_class_dir / img.name)\n","\n","        for img in val_imgs:\n","            shutil.copy2(img, val_class_dir / img.name)\n","\n","        print(f\"✅ {class_dir.name}: {len(train_imgs)} train, {len(val_imgs)} val\")\n","\n","    print(\"🎉 Dataset split into train/val complete.\")\n","\n","# === USAGE ===\n","prepare_dataset(\"/content/tomato_ds\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1749960454154,"user":{"displayName":"Root","userId":"10400991980939663586"},"user_tz":-180},"id":"MI0AB6enxQ_S"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":134400,"status":"ok","timestamp":1749973247678,"user":{"displayName":"Root","userId":"10400991980939663586"},"user_tz":-180},"id":"Gj4S43rYhG6d","outputId":"6418868f-ddf8-420f-8582-a565d0e81901"},"outputs":[{"name":"stderr","output_type":"stream","text":["TRAIN: 100%|██████████| 218/218 [00:23<00:00,  9.32it/s]\n","VAL: 100%|██████████| 55/55 [00:02<00:00, 24.42it/s]\n","TRAIN: 100%|██████████| 218/218 [00:24<00:00,  8.94it/s]\n","VAL: 100%|██████████| 55/55 [00:02<00:00, 23.32it/s]\n","TRAIN: 100%|██████████| 218/218 [00:23<00:00,  9.10it/s]\n","VAL: 100%|██████████| 55/55 [00:02<00:00, 23.95it/s]\n","TRAIN: 100%|██████████| 218/218 [00:24<00:00,  9.04it/s]\n","VAL: 100%|██████████| 55/55 [00:02<00:00, 23.76it/s]\n","TRAIN: 100%|██████████| 218/218 [00:23<00:00,  9.23it/s]\n","VAL: 100%|██████████| 55/55 [00:02<00:00, 23.57it/s]\n"]}],"source":["# 🚀 Colab Setup: Install Dependencies\n","# !pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n","# !pip install -q albumentations==1.3.1\n","# !pip install -q scikit-learn\n","# !pip install -q matplotlib seaborn\n","# !pip install -q tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, models\n","from torchvision.models import EfficientNet_B0_Weights\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from sklearn.metrics import f1_score, confusion_matrix\n","import numpy as np\n","import cv2\n","import copy\n","import os\n","from pathlib import Path\n","import logging\n","from tqdm import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import urllib.request\n","import hashlib\n","\n","# --------------------- Setup Logging ---------------------\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    handlers=[logging.StreamHandler(), logging.FileHandler(\"training_log_v5.txt\")]\n",")\n","logger = logging.getLogger(__name__)\n","\n","# Set random seed for reproducibility\n","def set_seed(seed=42):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","set_seed(42)\n","\n","# --------------------- Setup ---------------------\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","logger.info(f\"🚀 Device: {device}\")\n","\n","DATA_ROOT = Path(\"/content\")\n","TRAIN_DIR = DATA_ROOT / \"train\"\n","VAL_DIR = DATA_ROOT / \"val\"\n","\n","CONFIG = {\n","    'batch_size': 16,\n","    'epochs': 5,\n","    'patience': 3,\n","    'lr': 1e-3,\n","    'model_name': 'efficientnet_b0',\n","    'num_workers': 0,\n","}\n","\n","# ------------------ Transforms -------------------\n","train_tfms = A.Compose([\n","    A.Resize(224, 224),\n","    A.HorizontalFlip(p=0.5),\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ToTensorV2()\n","])\n","\n","val_tfms = A.Compose([\n","    A.Resize(224, 224),\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ToTensorV2()\n","])\n","\n","class AlbumentationsDataset(datasets.ImageFolder):\n","    def __init__(self, root, transform=None):\n","        super().__init__(root, transform=None, is_valid_file=self.is_valid_file)\n","        self.transform = transform\n","        self.samples = self._validate_samples()\n","        logger.info(f\"Valid samples in {root}: {len(self.samples)}\")\n","\n","    @staticmethod\n","    def is_valid_file(filename):\n","        valid_extensions = ('.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG')\n","        return filename.lower().endswith(valid_extensions)\n","\n","    def _validate_samples(self):\n","        if not self.samples:\n","            logger.error(f\"No valid images found in {self.root}. Check directory structure and file extensions.\")\n","            return []\n","        valid_samples = []\n","        for path, target in self.samples:\n","            try:\n","                img = cv2.imread(str(path))\n","                if img is None or img.size == 0:\n","                    logger.warning(f\"Skipping invalid image: {path}\")\n","                    continue\n","                valid_samples.append((path, target))\n","            except Exception as e:\n","                logger.warning(f\"Error validating {path}: {e}\")\n","        if not valid_samples:\n","            logger.error(f\"No valid images after validation in {self.root}.\")\n","        return valid_samples\n","\n","    def __getitem__(self, index):\n","        path, target = self.samples[index]\n","        try:\n","            image = cv2.imread(str(path))\n","            if image is None:\n","                raise ValueError(f\"Failed to load image: {path}\")\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            if self.transform:\n","                image = self.transform(image=image)['image']\n","            return image, target\n","        except Exception as e:\n","            logger.error(f\"Error loading {path}: {e}\")\n","            dummy = np.zeros((224, 224, 3), dtype=np.uint8)\n","            if self.transform:\n","                dummy = self.transform(image=dummy)['image']\n","            return dummy, target\n","\n","# ------------------ Load Data --------------------\n","try:\n","    if not TRAIN_DIR.exists() or not VAL_DIR.exists():\n","        raise FileNotFoundError(f\"Dataset directories not found: {TRAIN_DIR}, {VAL_DIR}\")\n","    train_ds = AlbumentationsDataset(TRAIN_DIR, transform=train_tfms)\n","    val_ds = AlbumentationsDataset(VAL_DIR, transform=val_tfms)\n","except Exception as e:\n","    logger.error(f\"Failed to load dataset: {e}\")\n","    raise\n","\n","if len(train_ds) == 0 or len(val_ds) == 0:\n","    logger.error(\"One or both datasets are empty. Check directory contents and file extensions.\")\n","    raise ValueError(\"Empty dataset\")\n","\n","class_names = train_ds.classes\n","num_classes = len(class_names)\n","logger.info(f\"📊 Classes: {num_classes} | Train: {len(train_ds)} | Val: {len(val_ds)}\")\n","\n","train_loader = DataLoader(\n","    train_ds, batch_size=CONFIG['batch_size'], shuffle=True,\n","    num_workers=CONFIG['num_workers']\n",")\n","val_loader = DataLoader(\n","    val_ds, batch_size=CONFIG['batch_size'], shuffle=False,\n","    num_workers=CONFIG['num_workers']\n",")\n","dataloaders = {'train': train_loader, 'val': val_loader}\n","\n","# ------------------- Model Builder -------------------\n","def build_model(model_name=CONFIG['model_name'], num_classes=15):\n","    try:\n","        weights_url = \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\"\n","        cache_dir = Path(\"/root/.cache/torch/hub/checkpoints\")\n","        cache_dir.mkdir(parents=True, exist_ok=True)\n","        weights_path = cache_dir / \"efficientnet_b0_rwightman-7f5810bc.pth\"\n","\n","        if not weights_path.exists():\n","            logger.info(f\"Downloading weights from {weights_url}\")\n","            urllib.request.urlretrieve(weights_url, weights_path)\n","\n","        model = models.efficientnet_b0(weights=None)\n","        state_dict = torch.load(weights_path, map_location=device)\n","        model.load_state_dict(state_dict, strict=False)\n","        in_features = model.classifier[1].in_features\n","        model.classifier = nn.Linear(in_features, num_classes)\n","        logger.info(f\"Model {model_name} initialized with manual weights\")\n","        return model.to(device)\n","    except Exception as e:\n","        logger.warning(f\"Failed to load pretrained weights: {e}. Falling back to random initialization.\")\n","        model = models.efficientnet_b0(weights=None)\n","        in_features = model.classifier[1].in_features\n","        model.classifier = nn.Linear(in_features, num_classes)\n","        logger.info(f\"Model {model_name} initialized without pretrained weights\")\n","        return model.to(device)\n","\n","model = build_model(num_classes=num_classes)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=CONFIG['lr'])\n","scheduler = CosineAnnealingLR(optimizer, T_max=CONFIG['epochs'], eta_min=1e-6)\n","\n","# ------------------- Training ---------------------\n","def train_model(model, dataloaders, epochs, patience):\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    train_losses, val_losses = [], []\n","    trigger = 0\n","    checkpoint_dir = Path(\"checkpoints_v5\")\n","    checkpoint_dir.mkdir(exist_ok=True)\n","\n","    with open(\"metrics_v5.csv\", \"w\") as f:\n","        f.write(\"epoch,phase,loss,accuracy\\n\")\n","\n","    for epoch in range(epochs):\n","        logger.info(f\"\\n📅 Epoch {epoch+1}/{epochs}\")\n","        for phase in ['train', 'val']:\n","            model.train() if phase == 'train' else model.eval()\n","            running_loss, correct, total = 0.0, 0, 0\n","            preds_all, labels_all = [], []\n","\n","            try:\n","                for batch_idx, (inputs, labels) in enumerate(tqdm(dataloaders[phase], desc=phase.upper())):\n","                    inputs, labels = inputs.to(device), labels.to(device)\n","                    optimizer.zero_grad()\n","\n","                    with torch.set_grad_enabled(phase == 'train'):\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","                        if phase == 'train':\n","                            loss.backward()\n","                            optimizer.step()\n","\n","                    preds = outputs.argmax(dim=1)\n","                    preds_all.extend(preds.cpu().numpy())\n","                    labels_all.extend(labels.cpu().numpy())\n","                    running_loss += loss.item() * inputs.size(0)\n","                    correct += (preds == labels).sum().item()\n","                    total += labels.size(0)\n","\n","                    batch_acc = (preds == labels).float().mean().item()\n","                    logger.info(f\"Batch {batch_idx+1}: Loss: {loss.item():.4f}, Acc: {batch_acc:.4f}\")\n","\n","            except Exception as e:\n","                logger.error(f\"Error in {phase} phase: {e}\")\n","                raise\n","\n","            epoch_loss = running_loss / total if total > 0 else float('inf')\n","            epoch_acc = correct / total if total > 0 else 0.0\n","            epoch_f1 = f1_score(labels_all, preds_all, average='macro') if labels_all else 0.0\n","\n","            logger.info(f\"🔸 {phase.title()} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f} | F1: {epoch_f1:.4f}\")\n","\n","            with open(\"metrics_v5.csv\", \"a\") as f:\n","                f.write(f\"{epoch+1},{phase},{epoch_loss:.4f},{epoch_acc:.4f}\\n\")\n","\n","            if phase == 'val':\n","                scheduler.step()\n","                val_losses.append(epoch_loss)\n","\n","                torch.save({\n","                    'epoch': epoch,\n","                    'model_state_dict': model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'loss': epoch_loss,\n","                    'accuracy': epoch_acc\n","                }, checkpoint_dir / f\"model_epoch_{epoch}.pth\")\n","                logger.info(f\"💾 Checkpoint saved: model_epoch_{epoch}.pth\")\n","\n","                if epoch_acc > best_acc:\n","                    best_acc = epoch_acc\n","                    best_model_wts = copy.deepcopy(model.state_dict())\n","                    torch.save(best_model_wts, checkpoint_dir / \"best_model_v5.pth\")\n","                    logger.info(\"💾 Best model saved: best_model_v5.pth\")\n","                else:\n","                    trigger += 1\n","            else:\n","                train_losses.append(epoch_loss)\n","\n","            if trigger >= patience:\n","                logger.info(\"⛔ Early stopping activated.\")\n","                break\n","\n","    model.load_state_dict(best_model_wts)\n","    logger.info(f\"\\n🏆 Best Val Accuracy: {best_acc:.4f}\")\n","\n","    torch.save(model.state_dict(), \"nucleusV5_weights.pth\")\n","    torch.save(model, \"nucleusV5_model.pth\")\n","    logger.info(\"💾 Final model saved as nucleusV5_model.pth and nucleusV5_weights.pth\")\n","\n","    return model, train_losses, val_losses, preds_all, labels_all\n","\n","# ------------------ Train & Save -------------------\n","try:\n","    model, train_losses, val_losses, preds_all, labels_all = train_model(model, dataloaders, CONFIG['epochs'], CONFIG['patience'])\n","except Exception as e:\n","    logger.error(f\"Training failed: {e}\")\n","    raise\n","\n","# ------------------- Visualizations -----------------\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":65,"status":"ok","timestamp":1749966724878,"user":{"displayName":"Root","userId":"10400991980939663586"},"user_tz":-180},"id":"_v0y7GE3xW3Q"},"outputs":[],"source":["# ------------------ Train & Save -------------------\n","# model, train_losses, val_losses, preds_all, labels_all = train_model(model, dataloaders, CONFIG['epochs'], CONFIG['patience'])\n","\n","# Save both state dict and full model\n","# torch.save(model.state_dict(), \"nucleusV4_weights.pth\")\n","# torch.save(model, \"nucleusV4_model.pth\")\n","# logger.info(\"💾 Model saved as nucleusV4_model.pth and nucleusV4_weights.pth\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPAlDOlWTI2Ouc8aRKOp6mZ","gpuType":"T4","mount_file_id":"1ejLb8aY6NtN-dQa9o0G5U5mtll-ddYjM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
